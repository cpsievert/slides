{
    "contents" : "---\ntitle: \"Web scraping in R\"\nauthor: \"Carson Sievert\"\ndate: \"Follow along -- <http://cpsievert.github.io/slides/web-scraping>\"\noutput: \n  ioslides_presentation:\n          incremental: true\n          widescreen: true\n---\n\n```{r setup, echo=FALSE, message=FALSE}\nlibrary(knitr)\nopts_chunk$set(message = FALSE, cache = TRUE, warning = FALSE)\n```\n\n## Data is messy (especially on the web)!\n\n* As statisticians, we typically think of data in a [tidy](http://vita.had.co.nz/papers/tidy-data.pdf) (i.e., tabular) format. That is\n    * rows == observations (often sharing an observational unit)\n    * columns == various observational attributes\n* This is a convenient statistical modeling framework, but data hardly ever begins in this tidy format (especially on the web).\n* This talk will provide a quick overview of popular methods for acquiring info/data from the web using R.\n* If you get nothing else from this talk, just remember to...\n\n---\n\n<div align = \"center\">\n  <img src = \"view-the-source.jpg\" width = \"1000\" height = \"600\">\n</div>\n\n## Motivating Example\n\n<iframe src = \"http://en.wikipedia.org/wiki/Table_%28information%29\" width = \"800px\" height = \"600px\"></iframe>\n\n---\n\n[rvest](https://github.com/hadley/rvest) is a nice R package for web-scraping by (you guessed it) Hadley Wickham.\n\n```{r, eval=FALSE, echo=FALSE}\nlibrary(XML)\ndoc <- htmlParse(\"http://en.wikipedia.org/wiki/Table_(information)\")\nnode <- getNodeSet(doc, \"//table[@class='wikitable']\")\nreadHTMLTable(node[[1]])\n```\n\n```{r}\nlibrary(rvest)\n# First, grab the page source\nhtml(\"http://en.wikipedia.org/wiki/Table_(information)\") %>%\n  # then extract the first node with class of wikitable\n  html_node(\".wikitable\") %>% \n  # then convert the HTML table into a data frame\n  html_table()\n```\n\n* __Note__: `html_table` only works on 'nicely' formatted HTML tables.\n\n---\n\nThis is a nice format? Really? Yes, really. It's the format used to render tables on webpages.\n\n```html\n<table class=\"wikitable\">\n  <tr>\n    <th>First name</th>\n    <th>Last name</th>\n    <th>Age</th>\n  </tr>\n  <tr>\n    <td>Bielat</td>\n    <td>Adamczak</td>\n    <td>24</td>\n  </tr>\n  <tr>\n    <td>Blaszczyk</td>\n    <td>Kostrzewski</td>\n    <td>25</td>\n  </tr>\n  <tr>\n    <td>Olatunkboh</td>\n    <td>Chijiaku</td>\n    <td>22</td>\n  </tr>\n</table> \n```\n\n# What if we want info that isn't packaged neatly in `<table>`?\n\n## (selectorgadget + rvest) to the rescue!\n\n* [Selectorgadget](http://selectorgadget.com/) is a [Chrome browser extension](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en) for quickly identifying/selecting parts of an HTML page.\n* With some user feedback, the gadget will tell you what [CSS selector](http://www.w3.org/TR/2011/REC-css3-selectors-20110929/) will return the highlighted page elements.\n* Let's try it out on [this page](http://www.sec.gov/litigation/suspensions.shtml)\n\n## Extracting links to reports\n\n```{r}\nhtml(\"http://www.sec.gov/litigation/suspensions.shtml\") %>%\n    html_nodes(\"p+ table a\") %>% head\n```\n\n```{r}\nhtml(\"http://www.sec.gov/litigation/suspensions.shtml\") %>%\n    html_nodes(\"p+ table a\") %>% html_attr(name=\"href\") %>% head\n```\n\n## Your turn\n\n* Extract links to the personal websites of all ISU Statistics Faculty -- <http://www.stat.iastate.edu/people/faculty/>\n* __Hint__: selectorgadget will be useful here!\n\n## Your turn solution\n\n```{r}\nhtml(\"http://www.stat.iastate.edu/people/faculty/\") %>%\n  html_nodes(\"#content a\") %>% html_attr(name=\"href\") -> hrefs\nhead(hrefs)\n```\n\n## Access the DOM with RSelenium\n\nUseful if you need access to the [DOM](http://en.wikipedia.org/wiki/Document_Object_Model), not just the page source.\n\nJust to demo, let's browse through faculty pages.\n\n```{r, eval = FALSE}\nlibrary(RSelenium)\nstartServer()\nremDr <- remoteDriver(browserName=\"firefox\")\nremDr$open()\nfor (i in hrefs) {\n  Sys.sleep(2)\n  remDr$navigate(i) # at this point, you could remDr$getPageSource()\n}\n```\n\n* We use RSelenium to test whether [animint](https://github.com/tdhock/animint) interactive plots behave correctly.\n* I've also used it to scrape websites that have to be rendered in a browser in order to access certain info.\n\n## Common data exchange formats\n\n* So far we've briefly covered how to extract information from HTML pages.\n* HTML is great for _sharing content_ between _people_, but it isn't great for _exchanging data_ between _machines_.\n* There are _a ton_ of different ways to exchange data over the web, but by far the most popular ones are XML and JSON.\n\n## What is XML?\n\nXML is a markup language that looks very similar to HTML.\n\n```xml\n<mariokart>\n  <driver name=\"Bowser\" occupation=\"Koopa\">\n    <vehicle speed=\"55\" weight=\"25\"> Wario Bike </vehicle>\n    <vehicle speed=\"40\" weight=\"67\"> Piranha Prowler </vehicle>\n  </driver>\n  <driver name=\"Peach\" occupation=\"Princess\">\n    <vehicle speed=\"54\" weight=\"29\"> Royal Racer </vehicle>\n    <vehicle speed=\"50\" weight=\"34\"> Wild Wing </vehicle>\n  </driver>\n</mariokart>\n```\n\n* This example shows that XML can (and is) used to store inherently tabular data ([thanks Jeroen Ooms for the fun example](http://arxiv.org/pdf/1403.2805v1.pdf))\n* What is are the observational units here? How many observations in total?\n* Two units and 6 total observations (4 vehicles and 2 drivers).\n\n---\n\n[XML2R](https://github.com/cpsievert/XML2R) is a framework to simplify acquistion of tabular/relational XML.\n\n```{r, eval = FALSE}\n# devtools::install_github(\"cpsievert/XML2R\")\nlibrary(XML2R)\nobs <- XML2Obs(\"http://bit.ly/mario-xml\")\ntable(names(obs))\n```\n\n```{r, echo = FALSE}\n# hopefully no one is watching\nlibrary(XML2R)\nobs <- XML2Obs(\"http://bit.ly/mario-xml\", quiet = TRUE)\ntable(names(obs))\n```\n\n---\n\n```{r}\nobs # named list of matrices. Each matrix is *guaranteed* to have 1 row.\n```\n\n---\n\n```{r}\ncollapse_obs(obs) # groups observations by their name/unit\n```\n\n* What information have I lost by combining observations of the same unit into the same table?\n* I can't map vehicles to the drivers!\n\n---\n\n```{r}\nobs <- add_key(obs, parent = \"mariokart//driver\", recycle = \"name\")\ncollapse_obs(obs)\n```\n\n---\n\nNow (if I want) I can merge the tables into a single table...\n\n```{r}\ntabs <- collapse_obs(obs)\nmerge(tabs[[1]], tabs[[2]], by = \"name\")\n```\n\n## Your turn\n\nTurn this XML file into a set of tables (using XML2R) -- <http://gd2.mlb.com/components/game/mlb/year_2011/month_04/day_04/gid_2011_04_04_minmlb_nyamlb_1/players.xml>\n\n## Your turn 'solution'\n\nUsing `add_key` is optional here, but it removes the need to hang on to the \"game\" table.\n\n```{r, results='hide'}\nlibrary(magrittr)\nXML2Obs(\"http://gd2.mlb.com/components/game/mlb/year_2011/month_04/day_04/gid_2011_04_04_minmlb_nyamlb_1/players.xml\") %>% \n  add_key(parent = \"game\", recycle = \"venue\") %>% \n  add_key(parent = \"game\", recycle = \"date\") %>%\n  collapse_obs -> tabs\n```\n\n```{r}\ntabs[[\"game//team//player\"]][1:5, c(\"first\", \"last\", \"venue\", \"date\")]\n```\n\n## What about JSON?\n\n* JavaScript Object Notation (JSON) is comprised of two components:\n    1. arrays => [value1, value2]\n    2. objects => {\"key1\": value1, \"key2\": [value2, value3]} \n* NOTE: you can also have arrays of objects!\n* The preferred R package for R <=> JSON conversion has long been [RJSONIO](http://cran.r-project.org/web/packages/RJSONIO/index.html)\n* However, [jsonlite](http://cran.r-project.org/web/packages/jsonlite/index.html) is gaining a lot of momentum/attention.\n* In fact, [shiny will soon be moving from RJSONIO to jsonlite](https://github.com/rstudio/shiny/issues/572)\n\n\n## Package downloads from RStudio's CRAN mirror\n\n<div align=\"center\">\n  <img src = \"json.png\" width = \"1000\" height = \"500\">\n</div>\n\n\n## Back to Mariokart {.smaller}\n\n```json\n[\n    {\n        \"driver\": \"Bowser\",\n        \"occupation\": \"Koopa\",\n        \"vehicles\": [\n            {\n                \"model\": \"Wario Bike\",\n                \"speed\": 55,\n                \"weight\": 25\n            },\n            {\n                \"model\": \"Piranha Prowler\",\n                \"speed\": 40,\n                \"weight\": 67\n            }\n        ]\n    },\n    {\n        \"driver\": \"Peach\",\n        \"occupation\": \"Princess\",\n        \"vehicles\": [\n            {\n                \"model\": \"Royal Racer\",\n                \"speed\": 54,\n                \"weight\": 29\n            },\n            {\n                \"model\": \"Wild Wing\",\n                \"speed\": 50,\n                \"weight\": 34\n            }\n        ]\n    }\n]\n```\n\n\n---\n\n```{r}\nlibrary(jsonlite)\nmario <- fromJSON(\"http://bit.ly/mario-json\")\nstr(mario) # nested data.frames?!? \n```\n\n---\n\n```{r}\nmario$driver\nmario$vehicles\n```\n\nHow do we get two tables (with a common id) like the XML example?\n\n---\n\n```{r}\n# this mapply statement is essentially equivalent to add_key\nvehicles <- mapply(function(x, y) cbind(x, driver = y), \n                   mario$vehicles, mario$driver, SIMPLIFY = FALSE)\nrbind.pages(vehicles)\nmario[!grepl(\"vehicle\", names(mario))]\n```\n\n## Thanks! Any questions?\n\n<div align = \"center\">\n  <img src = \"http://mlblogsjaneheller.files.wordpress.com/2010/09/wave1.gif\" width = \"400\" height = \"400\">\n</div>\n\n\n",
    "created" : 1416243062214.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4251639388",
    "id" : "8C7DE24C",
    "lastKnownWriteTime" : 1416430965,
    "path" : "~/Desktop/github/local/cpsievert.github.com/slides/web-scraping/index.Rmd",
    "project_path" : "index.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}